{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow Experiments\n",
    "\n",
    "While MLflow does provide a default experiment, it primarily serves as a ‘catch-all’ safety net for runs initiated without a specified active experiment. However, it’s not recommended for regular use. Instead, creating unique experiments for specific collections of runs offers numerous advantages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow \n",
    "from mlflow_for_ml_dev.utils.utils import get_root_project\n",
    "from mlflow_for_ml_dev.experiments.exp_utils import print_experiment_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = get_root_project()\n",
    "tracking_uri = (root_folder / \"mlruns\").as_uri()\n",
    "mlflow.set_tracking_uri(tracking_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Experiment\n",
    "\n",
    "`get_experiment(experiment_id: str) → Experiment`\n",
    "\n",
    "Retrieve an experiment by experiment_id from the backend store\n",
    "\n",
    "Parameters:\n",
    "\n",
    "* experiment_id – The experiment ID returned from create_experiment.\n",
    "\n",
    "Returns:\n",
    "\n",
    "* mlflow.entities.Experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = mlflow.get_experiment(experiment_id=\"287893500299232581\")\n",
    "print_experiment_info(experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Experiment by name\n",
    "\n",
    "`get_experiment_by_name(name: str) → Optional[Experiment]`\n",
    "\n",
    "Retrieve an experiment by experiment name from the backend store\n",
    "\n",
    "Parameters:\n",
    "\n",
    "* name – The case sensitive experiment name.\n",
    "\n",
    "Returns:\n",
    "\n",
    "* An instance of mlflow.entities.Experiment if an experiment with the specified name exists, otherwise None.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = mlflow.get_experiment_by_name(name=\"first_experiment\")\n",
    "print_experiment_info(experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Experiments\n",
    "\n",
    "```\n",
    "mlflow.search_experiments(view_type: int = 1,\n",
    "                         max_results: Optional[int] = None,\n",
    "                         filter_string: Optional[str] = None,\n",
    "                         order_by: Optional[List[str]] = None\n",
    "                    )\n",
    "```\n",
    "\n",
    "Search for experiments that match the specified search query.\n",
    "\n",
    "Parameters: \n",
    "\n",
    "\n",
    "* view_type – One of enum values ACTIVE_ONLY, DELETED_ONLY, or ALL defined in mlflow.entities.ViewType.\n",
    "\n",
    "* max_results – If passed, specifies the maximum number of experiments desired. If not passed, all experiments will be returned.\n",
    "\n",
    "* filter_string –\n",
    "\n",
    "* order_by –"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**View type**\n",
    "\n",
    "* mlflow.tracking.client.ViewType.ACTIVE_ONLY\n",
    "* mlflow.tracking.client.ViewType.DELETE_ONLY\n",
    "* mlflow.tracking.client.ViewType.ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = mlflow.search_experiments(view_type=mlflow.tracking.client.ViewType.ALL)\n",
    "for experiment in experiments:\n",
    "    print_experiment_info(experiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Max Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = mlflow.search_experiments(view_type=mlflow.tracking.client.ViewType.ACTIVE_ONLY, max_results=1)\n",
    "for experiment in experiments:\n",
    "    print_experiment_info(experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Order By**\n",
    "\n",
    "The following fields are supported:\n",
    "\n",
    "* experiment_id: Experiment ID\n",
    "\n",
    "* name: Experiment name\n",
    "\n",
    "* creation_time: Experiment creation time\n",
    "\n",
    "* last_update_time: Experiment last update time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = mlflow.search_experiments(view_type=mlflow.tracking.client.ViewType.ACTIVE_ONLY, max_results=1, order_by=[\"last_update_time ASC\"])\n",
    "for experiment in experiments:\n",
    "    print_experiment_info(experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter String**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = mlflow.search_experiments(view_type=mlflow.tracking.client.ViewType.ACTIVE_ONLY, max_results=2, filter_string=\"name = 'second_experiment'\")\n",
    "for experiment in experiments:\n",
    "    print_experiment_info(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = mlflow.search_experiments(view_type=mlflow.tracking.client.ViewType.ACTIVE_ONLY,\n",
    "                                        max_results=2,\n",
    "                                        filter_string=\"tags.project_name = 'first_project'\",\n",
    "                                        order_by=[\"last_update_time ASC\"]\n",
    "                                    )\n",
    "for experiment in experiments:\n",
    "    print_experiment_info(experiment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
