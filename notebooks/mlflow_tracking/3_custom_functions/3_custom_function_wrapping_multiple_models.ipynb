{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Parameters to wrap multiple models in a single MLflow model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow_for_ml_dev.experiments.exp_utils import get_or_create_experiment\n",
    "from mlflow_for_ml_dev.utils.utils import get_root_project\n",
    "\n",
    "from mlflow_for_ml_dev.experiments.custom_models import MultiModel\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.models.signature import Schema\n",
    "from mlflow.types.schema import ColSpec\n",
    "from mlflow.types.schema import TensorSpec\n",
    "from mlflow.types.schema import ParamSpec\n",
    "from mlflow.types.schema import ParamSchema\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"wrapping_multiple_models\"\n",
    "tags = {\"project_name\":\"multiple_models\"}\n",
    "experiment = get_or_create_experiment(experiment_name=experiment_name, tags=tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris(as_frame=True)\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining signature of the model\n",
    "\n",
    "We can build the model signature using the corresponding classes from mlflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: \n",
      "  ['sepal length (cm)': float (required), 'sepal width (cm)': float (required), 'petal length (cm)': float (required), 'petal width (cm)': float (required)]\n",
      "outputs: \n",
      "  ['model_id': Tensor('int32', (-1,))]\n",
      "params: \n",
      "  ['model_id': string (default: rfc)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# defining input schema. In this case, we are using all the features as input\n",
    "input_schema = Schema([ColSpec(name=feature_name, type=\"float\") for feature_name in x_train.columns])\n",
    "\n",
    "# defining output schema. In this case, we are using the target as output\n",
    "output_schema = Schema([TensorSpec(name=\"model_id\", shape=(-1,), type=np.dtype(np.int32))]) \n",
    "\n",
    "# defining param schema. In this case, we are using the model_id as a parameter\n",
    "param_schema = ParamSchema(params = [ParamSpec(name=\"model_id\", dtype=\"string\", default=\"rfc\")])\n",
    "\n",
    "# defining the model signature\n",
    "model_signature = ModelSignature(inputs=input_schema, outputs=output_schema, params=param_schema)\n",
    "print(model_signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can infer the schema from the input and outputs of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model:  rfc\n",
      "Fitting model:  gbc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/31 15:26:26 INFO mlflow.types.utils: MLflow 2.9.0 introduces model signature with new data types for lists and dictionaries. For input such as Dict[str, Union[scalars, List, Dict]], we infer dictionary values types as `List -> Array` and `Dict -> Object`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with model:  rfc\n",
      "inputs: \n",
      "  ['sepal length (cm)': double (required), 'sepal width (cm)': double (required), 'petal length (cm)': double (required), 'petal width (cm)': double (required)]\n",
      "outputs: \n",
      "  ['rfc': Tensor('int32', (-1,))]\n",
      "params: \n",
      "  ['model_id': string (default: rfc)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\"rfc\":RandomForestClassifier(),\"gbc\": GradientBoostingClassifier()}\n",
    "\n",
    "model = MultiModel(models)\n",
    "\n",
    "# fitting the models\n",
    "model.fit_estimators(x_train, y_train)\n",
    "\n",
    "# getting the model predictions (output)\n",
    "output = model.predict(None, x_test,params={\"model_id\":\"rfc\"})\n",
    "\n",
    "# defining the model signature\n",
    "model_signature = infer_signature(model_input=x_train,model_output= output, params={\"model_id\":\"rfc\"})\n",
    "\n",
    "print(model_signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Logging the model with Signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model:  rfc\n",
      "Fitting model:  gbc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manue\\projects\\mlflow_for_ml_dev\\.venv\\Lib\\site-packages\\_distutils_hack\\__init__.py:11: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "c:\\Users\\manue\\projects\\mlflow_for_ml_dev\\.venv\\Lib\\site-packages\\_distutils_hack\\__init__.py:26: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "models = {\"rfc\":RandomForestClassifier(),\"gbc\": GradientBoostingClassifier()}\n",
    "multi_model = MultiModel(models=models)\n",
    "\n",
    "project_dir = get_root_project()\n",
    "code_path = project_dir / \"mlflow_for_ml_dev/experiments/custom_models.py\"\n",
    "# start mlflow run \n",
    "with mlflow.start_run(run_name=\"multi_model\", experiment_id=experiment.experiment_id) as run:\n",
    "    multi_model.fit_estimators(x_train, y_train)\n",
    "    mlflow.pyfunc.log_model(artifact_path=\"multi_model\", python_model=multi_model, signature=model_signature, code_path=[code_path])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring model\n",
    "\n",
    "Now we can use the same mlflow model to score both the Random Forest Classifier and Gradient Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = mlflow.pyfunc.load_model(model_uri=f\"runs:/{run.info.run_id}/multi_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with model:  rfc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rfc': array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "        0, 2, 2, 2, 2, 2, 0, 0])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(x_test, params={\"model_id\":\"rfc\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with model:  gbc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'gbc': array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "        0, 2, 2, 2, 2, 2, 0, 0])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(x_test, params={\"model_id\":\"gbc\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
