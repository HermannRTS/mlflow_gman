{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runs \n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"mlflow_run.jpeg\" alt=\"MLFlow Run\" />\n",
    "</div>\n",
    "\n",
    "\n",
    "A MLflow run is a unit of work in MLflow that represents the execution of a machine learning experiment or a piece of code. It tracks the parameters, metrics, artifacts, and metadata associated with the run. MLflow runs allow you to log and track experiments, compare different runs, and reproduce results. Each run is associated with an experiment and can have multiple tags, parameters, metrics, and artifacts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a MLflow Run\n",
    "\n",
    "### Using start_run\n",
    "\n",
    "```python\n",
    "mlflow.start_run()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/09 10:55:31 INFO mlflow.utils.credentials: Successfully connected to MLflow hosted tracking server! Host: https://adb-3088650010345545.5.azuredatabricks.net.\n"
     ]
    }
   ],
   "source": [
    "import mlflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"/Shared/Experiments/creating_runs\"\n",
    "tags = {\"project_name\":\"UNDEFINED\", \"topic\":\"run_management\"}\n",
    "experiment_id = mlflow.create_experiment(name=experiment_name, tags=tags)\n",
    "experiment = mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = mlflow.start_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlflow.tracking.fluent.ActiveRun"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine learing code here\n",
    "\n",
    "# logging parameters\n",
    "mlflow.log_param(\"param1\", 5)\n",
    "mlflow.log_param(\"param2\", 5)\n",
    "mlflow.log_param(\"param3\", 5)\n",
    "\n",
    "# logging metrics\n",
    "mlflow.log_metric(\"metric1\", 15)\n",
    "mlflow.log_metric(\"metric2\", 52)\n",
    "mlflow.log_metric(\"metric3\", 35)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Run with UUID 264556e274294e3caec3b0f9aeb82597 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#starting a new run\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m run2 \u001b[38;5;241m=\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\manue\\projects\\mlflow_for_ml_dev\\.venv\\Lib\\site-packages\\mlflow\\tracking\\fluent.py:306\u001b[0m, in \u001b[0;36mstart_run\u001b[1;34m(run_id, experiment_id, run_name, nested, tags, description, log_system_metrics)\u001b[0m\n\u001b[0;32m    304\u001b[0m experiment_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(experiment_id) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(experiment_id, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m experiment_id\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(_active_run_stack) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nested:\n\u001b[1;32m--> 306\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[0;32m    307\u001b[0m         (\n\u001b[0;32m    308\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun with UUID \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is already active. To start a new run, first end the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    309\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent run with mlflow.end_run(). To start a nested \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    310\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun, call start_run with nested=True\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    311\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(_active_run_stack[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id)\n\u001b[0;32m    312\u001b[0m     )\n\u001b[0;32m    313\u001b[0m client \u001b[38;5;241m=\u001b[39m MlflowClient()\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_id:\n",
      "\u001b[1;31mException\u001b[0m: Run with UUID 264556e274294e3caec3b0f9aeb82597 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True"
     ]
    }
   ],
   "source": [
    "#starting a new run\n",
    "run2 = mlflow.start_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting a new run\n",
    "run2 = mlflow.start_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating run providing more info\n",
    "run_tags = {\"tag1\": \"value1\", \"tag2\": \"value2\"}\n",
    "run3 = mlflow.start_run(\n",
    "    run_name=\"run_with_tags\",\n",
    "    tags=run_tags,\n",
    "    description=\"This is a run with tags\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using with statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> About `mlflow.start_run()`\n",
    "> \n",
    "> The return value of `mlflow.start_run()` can be used as a context manager within a `with` block. Otherwise, you must call `end_run()` to terminate the current run.\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "with mlflow.start_run() as run:\n",
    "    print(\"Log metrics and params\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mlflow.tracking.fluent.ActiveRun'>\n",
      "Active Run:  152cb83623ce4d3299223e87fbf128f7\n",
      "Active Run:  152cb83623ce4d3299223e87fbf128f7\n",
      "\n",
      " \n",
      "\n",
      "<class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "mlflow.end_run() # end the active run to start a new one\n",
    "with mlflow.start_run(run_name=\"Run 2\", experiment_id=experiment.experiment_id) as run:\n",
    "\n",
    "    # Your ML code here\n",
    "\n",
    "    \n",
    "    active_run = mlflow.active_run()\n",
    "    print(type(active_run))  \n",
    "    print(\"Active Run: \", run.info.run_id)\n",
    "    print(\"Active Run: \", active_run.info.run_id)\n",
    "    print(\"\\n \\n\")\n",
    "\n",
    "\n",
    "# outside the with block\n",
    "active_run = mlflow.active_run()\n",
    "print(type(active_run))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_run == None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = mlflow.MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "created_run = client.create_run(experiment_id=experiment.experiment_id, run_name=\"test_run\", tags={\"tag1\": \"value1\", \"tag2\": \"value2\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlflow.entities.run.Run"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(created_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = mlflow.active_run()\n",
    "type(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlflow.tracking.fluent.ActiveRun"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loging to MLflow without an active run will create a new run\n",
    "mlflow.log_param(\"param1\", 5)\n",
    "run = mlflow.active_run()\n",
    "type(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.set_terminated(run_id=created_run.info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating Run Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end the active run to start a new one\n",
    "mlflow.end_run()\n",
    "with mlflow.start_run(run_name=\"Run 3\", experiment_id=experiment.experiment_id) as run:\n",
    "    # set a single tag\n",
    "    mlflow.set_tag(\"tag3\", \"value3\")\n",
    "    \n",
    "    # Set multiple tags\n",
    "    mlflow.set_tags({\"tag4\": \"value4\", \"tag5\": \"value5\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update run description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"Run 4\", experiment_id=experiment.experiment_id) as run:\n",
    "    #Update description\n",
    "    mlflow.set_tag(\"mlflow.note.content\", \"This is a new description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# including markdown\n",
    "with mlflow.start_run(run_name=\"Run 5\", experiment_id=experiment.experiment_id) as run:\n",
    "    #Update description\n",
    "    mlflow.set_tag(\"mlflow.note.content\", \"# This is a new description\")\n",
    "\n",
    "    mlflow.log_param(\"param1\", 5)\n",
    "    mlflow.log_metric(\"metric1\", 15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve run information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = mlflow.get_run(run_id = run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run_uuid: \"bf53b5489b7245788385e1e2c81f6346\"\n",
       "experiment_id: \"2988314006065978\"\n",
       "run_name: \"Run 5\"\n",
       "user_id: \"\"\n",
       "status: FINISHED\n",
       "start_time: 1717970274139\n",
       "end_time: 1717970275507\n",
       "artifact_uri: \"dbfs:/databricks/mlflow-tracking/2988314006065978/bf53b5489b7245788385e1e2c81f6346/artifacts\"\n",
       "lifecycle_stage: \"active\"\n",
       "run_id: \"bf53b5489b7245788385e1e2c81f6346\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.info.to_proto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "metrics {\n",
       "  key: \"metric1\"\n",
       "  value: 15\n",
       "  timestamp: 1717970275218\n",
       "  step: 0\n",
       "}\n",
       "params {\n",
       "  key: \"param1\"\n",
       "  value: \"5\"\n",
       "}\n",
       "tags {\n",
       "  key: \"mlflow.note.content\"\n",
       "  value: \"# This is a new description\"\n",
       "}\n",
       "tags {\n",
       "  key: \"mlflow.runName\"\n",
       "  value: \"Run 5\"\n",
       "}\n",
       "tags {\n",
       "  key: \"mlflow.source.name\"\n",
       "  value: \"c:\\\\Users\\\\manue\\\\projects\\\\mlflow_for_ml_dev\\\\.venv\\\\Lib\\\\site-packages\\\\ipykernel_launcher.py\"\n",
       "}\n",
       "tags {\n",
       "  key: \"mlflow.source.type\"\n",
       "  value: \"LOCAL\"\n",
       "}\n",
       "tags {\n",
       "  key: \"mlflow.user\"\n",
       "  value: \"manuel.gil-m@outlook.com\"\n",
       "}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.data.to_proto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
