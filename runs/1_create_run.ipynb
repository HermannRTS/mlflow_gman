{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runs \n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"mlflow_run.jpeg\" alt=\"MLFlow Run\" />\n",
    "</div>\n",
    "\n",
    "\n",
    "A MLflow run is a unit of work in MLflow that represents the execution of a machine learning experiment or a piece of code. It tracks the parameters, metrics, artifacts, and metadata associated with the run. MLflow runs allow you to log and track experiments, compare different runs, and reproduce results. Each run is associated with an experiment and can have multiple tags, parameters, metrics, and artifacts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a MLflow Run\n",
    "\n",
    "### Using start_run\n",
    "\n",
    "```python\n",
    "mlflow.start_run()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow \n",
    "from mlflow_for_ml_dev.utils.utils import get_root_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the artifact location to the experiments folder in the root project\n",
    "artifact_location = get_root_project() / \"runs\" / \"mlruns\"\n",
    "\n",
    "mlflow.set_tracking_uri(artifact_location.as_uri())\n",
    "print(artifact_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"runs-02\"\n",
    "tags = {\"project_name\":\"UNDEFINED\", \"topic\":\"run_management\"}\n",
    "experiment_id = mlflow.create_experiment(name=experiment_name, tags=tags)\n",
    "experiment = mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = mlflow.start_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.info.to_proto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.data.to_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine learing code here\n",
    "\n",
    "# logging parameters\n",
    "mlflow.log_param(\"param1\", 5)\n",
    "mlflow.log_param(\"param2\", 5)\n",
    "mlflow.log_param(\"param3\", 5)\n",
    "\n",
    "# logging metrics\n",
    "mlflow.log_metric(\"metric1\", 15)\n",
    "mlflow.log_metric(\"metric2\", 52)\n",
    "mlflow.log_metric(\"metric3\", 35)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the updated run object\n",
    "run = mlflow.get_run(run_id=run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.data.to_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting a new run without ending the previous one will throw an error\n",
    "run2 = mlflow.start_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To start a new run, first end the current run with mlflow.end_run().\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting a new run\n",
    "run2 = mlflow.start_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Providing more run metadata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating run providing more info\n",
    "run_tags = {\"tag1\": \"value1\", \"tag2\": \"value2\"}\n",
    "run3 = mlflow.start_run(\n",
    "    run_name=\"run_with_tags\",\n",
    "    tags=run_tags,\n",
    "    description=\"This is a run with tags\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using with statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> About `mlflow.start_run()`\n",
    "> \n",
    "> The return value of `mlflow.start_run()` can be used as a context manager within a `with` block. Otherwise, you must call `end_run()` to terminate the current run.\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "with mlflow.start_run() as run:\n",
    "    print(\"Log metrics and params\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run() # end the active run to start a new one\n",
    "with mlflow.start_run(run_name=\"Run 2\", experiment_id=experiment.experiment_id) as run:\n",
    "\n",
    "    # Your ML code here\n",
    "\n",
    "    \n",
    "    active_run = mlflow.active_run()\n",
    "    print(type(active_run))  \n",
    "    print(\"Active Run: \", run.info.run_id)\n",
    "    print(\"Active Run: \", active_run.info.run_id)\n",
    "    print(\"\\n \\n\")\n",
    "\n",
    "\n",
    "# outside the with block\n",
    "active_run = mlflow.active_run()\n",
    "print(type(active_run))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_run == None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = mlflow.MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "created_run = client.create_run(experiment_id=experiment.experiment_id, run_name=\"test_run\", tags={\"tag1\": \"value1\", \"tag2\": \"value2\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(created_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = mlflow.active_run()\n",
    "type(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loging to MLflow without an active run will create a new run automatically\n",
    "mlflow.log_param(\"param1\", 5)\n",
    "run = mlflow.active_run()\n",
    "type(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End the active run\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.set_terminated(run_id=created_run.info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating Run Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end the active run to start a new one\n",
    "mlflow.end_run()\n",
    "with mlflow.start_run(run_name=\"Run 3\", experiment_id=experiment.experiment_id) as run:\n",
    "    # set a single tag\n",
    "    mlflow.set_tag(\"tag3\", \"value3\")\n",
    "    \n",
    "    # Set multiple tags\n",
    "    mlflow.set_tags({\"tag4\": \"value4\", \"tag5\": \"value5\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update run description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"Run 4\", experiment_id=experiment.experiment_id) as run:\n",
    "    #Update description\n",
    "    mlflow.set_tag(\"mlflow.note.content\", \"This is a new description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# including markdown\n",
    "with mlflow.start_run(run_name=\"Run 5\", experiment_id=experiment.experiment_id) as run:\n",
    "    #Update description\n",
    "    mlflow.set_tag(\"mlflow.note.content\", \"# This is a new description\")\n",
    "\n",
    "    mlflow.log_param(\"param1\", 5)\n",
    "    mlflow.log_metric(\"metric1\", 15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve run information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = mlflow.get_run(run_id = run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.info.to_proto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.data.to_proto()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
